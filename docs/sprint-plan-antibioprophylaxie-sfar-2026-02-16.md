# Sprint Plan : Antibioprophylaxie SFAR

**Date :** 2026-02-16
**Scrum Master :** Thomas Boulier (assist√© par Claude)
**Niveau de projet :** 2

**Documents de r√©f√©rence :**
- PRD : docs/prd-antibioprophylaxie-sfar-2026-02-15.md
- Architecture : docs/architecture-antibioprophylaxie-sfar-2026-02-16.md
- UX Design : docs/ux-design-antibioprophylaxie-sfar-2026-02-16.md

---

## R√©sum√©

| M√©trique | Valeur |
|----------|--------|
| Stories | 19 |
| Points totaux | 78 |
| Milestones | 3 |
| Rythme | Pas de sprints chronom√©tr√©s ‚Äî story par story, au rythme du porteur de projet |

**Mode op√©ratoire :** Claude Code fait le d√©veloppement, Thomas supervise et valide. Tout est trac√© sur GitHub (issues, milestones, project board) via `gh` CLI.

**Objectif :** V1 compl√®te avant le congr√®s SFAR (septembre 2026).

---

## Inventaire des stories

### Milestone 1 : Structuration des donn√©es (EPIC-001)

> **Objectif :** Extraire les donn√©es du PDF RFE 2024 en formats exploitables (JSON + Excel), valid√©s cliniquement.
>
> **Livrable :** `data/rfe.json` + `data/rfe.xlsx` complets et valid√©s.
>
> **Approche :** It√©rative ‚Äî on commence par un tableau pilote (une sp√©cialit√©), on se met d'accord sur le format, puis on it√®re sur les autres.

---

#### S-001 : Init projet ‚Äî repo GitHub, structure, CI, CONTRIBUTING.md

**Epic :** EPIC-001
**Priorit√© :** Must Have
**Points :** 3

**User Story :**
En tant que d√©veloppeur (humain ou IA),
je veux un repo GitHub initialis√© avec la structure du projet, la CI et un guide de contribution,
afin de pouvoir contribuer efficacement d√®s le d√©part.

**Crit√®res d'acceptation :**
- [ ] Repo GitHub public cr√©√© avec `gh`
- [ ] Structure de dossiers conforme √† l'architecture (`app/`, `data/`, `tests/`, etc.)
- [ ] `pyproject.toml` avec les d√©pendances (FastAPI, uvicorn, pytest, ruff, etc.)
- [ ] `CONTRIBUTING.md` universel (humains + IAs) : conventions de code, git flow, conventional commits, principes (KISS, YAGNI), comment lancer le projet
- [ ] `CLAUDE.md` avec instructions sp√©cifiques Claude Code (r√©f√®re au CONTRIBUTING.md)
- [ ] `.github/workflows/ci.yml` : lint (ruff) + tests (pytest) sur push/PR
- [ ] `README.md` minimal (description du projet, statut, liens vers la doc)
- [ ] Milestones et labels cr√©√©s sur GitHub avec `gh`
- [ ] Issues cr√©√©es pour toutes les stories avec `gh`

**Notes techniques :**
- Utiliser `uv` comme gestionnaire de paquets
- Pre-commit hooks : ruff check + ruff format
- Labels GitHub : `epic:data`, `epic:webapp`, `epic:ia`, `priority:must`, `priority:should`, `priority:could`

**D√©pendances :** Aucune

---

#### S-002 : Extraire le 1er tableau (pilote) en JSON

**Epic :** EPIC-001
**Priorit√© :** Must Have
**Points :** 5

**User Story :**
En tant que d√©veloppeur,
je veux extraire les donn√©es d'un premier tableau du PDF RFE (une sp√©cialit√©) en JSON structur√©,
afin de valider le format de donn√©es avec le clinicien avant d'it√©rer sur les autres.

**Crit√®res d'acceptation :**
- [ ] Un fichier `data/rfe.json` avec la structure d√©finie dans l'architecture (mod√®le Intervention, Protocole, AlternativeAllergie)
- [ ] Au moins une sp√©cialit√© compl√®te (suggestion : Orthop√©die ‚Äî tableau bien structur√©)
- [ ] Chaque intervention contient : mol√©cule, posologie, timing, r√©injection, dur√©e, alternative allergie, source (page + tableau)
- [ ] Les cas "pas d'ABP recommand√©e" sont g√©r√©s
- [ ] Validation Pydantic du JSON (script de validation)

**Notes techniques :**
- Extraction manuelle ou semi-automatique depuis le PDF (Claude peut lire le PDF et extraire)
- Le format JSON est celui d√©fini dans l'architecture (section 5)
- Cr√©er un script `scripts/validate_data.py` qui charge le JSON et valide avec Pydantic

**D√©pendances :** S-001

---

#### S-003 : Cr√©er l'export Excel du 1er tableau

**Epic :** EPIC-001
**Priorit√© :** Must Have
**Points :** 2

**User Story :**
En tant que chercheur,
je veux un export Excel des donn√©es du premier tableau,
afin de disposer du niveau 2 de structuration pour l'√©tude comparative RAG.

**Crit√®res d'acceptation :**
- [ ] Fichier `data/rfe.xlsx` g√©n√©r√© √† partir du JSON
- [ ] Une feuille par sp√©cialit√©, colonnes : intervention, mol√©cule, posologie, timing, r√©injection, dur√©e, allergie, source
- [ ] Script reproductible (`scripts/json_to_excel.py`)

**Notes techniques :**
- Utiliser openpyxl pour la g√©n√©ration
- Le format Excel doit ressembler aux tableaux du PDF original (pour le niveau 2 du RAG)

**D√©pendances :** S-002

---

#### S-004 : Extraire les tableaux restants en JSON

**Epic :** EPIC-001
**Priorit√© :** Must Have
**Points :** 5

**User Story :**
En tant que d√©veloppeur,
je veux extraire toutes les sp√©cialit√©s restantes du PDF en JSON,
afin d'avoir une couverture √† 100% des interventions de la RFE.

**Crit√®res d'acceptation :**
- [ ] Toutes les sp√©cialit√©s de la RFE sont pr√©sentes dans `data/rfe.json`
- [ ] 100% des interventions list√©es dans les tableaux du PDF
- [ ] Validation Pydantic r√©ussie sur l'ensemble
- [ ] Validation clinique par Thomas (sp√©cialit√© par sp√©cialit√©)

**Notes techniques :**
- It√©rer sp√©cialit√© par sp√©cialit√©
- Le format est stabilis√© depuis S-002
- Thomas valide au fur et √† mesure

**D√©pendances :** S-002 (format valid√©)

---

#### S-005 : Compl√©ter l'export Excel pour toutes les sp√©cialit√©s

**Epic :** EPIC-001
**Priorit√© :** Must Have
**Points :** 2

**User Story :**
En tant que chercheur,
je veux l'export Excel complet de toutes les sp√©cialit√©s,
afin de disposer du dataset complet pour le RAG niveau 2.

**Crit√®res d'acceptation :**
- [ ] `data/rfe.xlsx` contient toutes les sp√©cialit√©s
- [ ] G√©n√©r√© automatiquement par `scripts/json_to_excel.py`

**D√©pendances :** S-004

---

#### S-006 : Structurer les recommandations g√©n√©rales

**Epic :** EPIC-001
**Priorit√© :** Should Have
**Points :** 3

**User Story :**
En tant qu'anesth√©siste,
je veux acc√©der aux recommandations g√©n√©rales transverses (timing, ob√©sit√©, insuffisance r√©nale, etc.),
afin de compl√©ter l'information des protocoles par intervention.

**Crit√®res d'acceptation :**
- [ ] Section `recommandations_generales` dans `data/rfe.json`
- [ ] Au minimum : timing d'administration, patient ob√®se, insuffisance r√©nale, dur√©e de prolongation
- [ ] Lien source (page PDF) pour chaque recommandation

**D√©pendances :** S-002 (format JSON stabilis√©)

---

### Milestone 2 : Webapp + API REST (EPIC-002)

> **Objectif :** Webapp responsive fonctionnelle avec recherche instantan√©e, navigation par arborescence, et API REST publique.
>
> **Livrable :** Application d√©ploy√©e sur le NAS, consultable par les coll√®gues.

---

#### S-007 : Backend FastAPI ‚Äî mod√®les Pydantic, chargement JSON, config

**Epic :** EPIC-002
**Priorit√© :** Must Have
**Points :** 3

**User Story :**
En tant que d√©veloppeur,
je veux le squelette FastAPI fonctionnel qui charge les donn√©es JSON au d√©marrage,
afin de servir de base √† l'API et aux pages web.

**Crit√®res d'acceptation :**
- [ ] `app/main.py` d√©marre avec Uvicorn
- [ ] Mod√®les Pydantic dans `app/data/models.py` (conformes √† l'architecture)
- [ ] `app/data/loader.py` charge `data/rfe.json` en m√©moire au d√©marrage
- [ ] Endpoint `/api/v1/health` fonctionnel
- [ ] Tests unitaires pour le loader et les mod√®les
- [ ] Configuration via variables d'environnement (`.env`)

**D√©pendances :** S-002 (au moins les donn√©es pilote)

---

#### S-008 : API REST ‚Äî endpoints interventions, sp√©cialit√©s

**Epic :** EPIC-002
**Priorit√© :** Must Have
**Points :** 5

**User Story :**
En tant que d√©veloppeur externe,
je veux une API REST document√©e pour interroger les recommandations,
afin d'int√©grer les donn√©es dans mes propres outils.

**Crit√®res d'acceptation :**
- [ ] `GET /api/v1/interventions` ‚Äî liste (+ filtre `?q=` et `?specialite=`)
- [ ] `GET /api/v1/interventions/{id}` ‚Äî d√©tail
- [ ] `GET /api/v1/specialites` ‚Äî liste avec nombre d'interventions
- [ ] `GET /api/v1/specialites/{id}` ‚Äî d√©tail avec interventions
- [ ] `GET /api/v1/recommandations` ‚Äî recommandations g√©n√©rales
- [ ] Documentation Swagger auto-g√©n√©r√©e sur `/docs`
- [ ] Tests d'int√©gration pour chaque endpoint
- [ ] R√©ponses JSON conformes aux sch√©mas Pydantic

**D√©pendances :** S-007

---

#### S-009 : Recherche fuzzy type-ahead

**Epic :** EPIC-002
**Priorit√© :** Must Have
**Points :** 5

**User Story :**
En tant qu'anesth√©siste,
je veux taper quelques lettres et voir les r√©sultats appara√Ætre instantan√©ment,
afin de trouver le bon protocole en moins de 5 secondes.

**Crit√®res d'acceptation :**
- [ ] Recherche fuzzy (tol√®re les fautes de frappe) dans `app/data/search.py`
- [ ] R√©sultats < 200ms (NFR-001)
- [ ] Recherche sur : nom d'intervention, sp√©cialit√©, mol√©cule
- [ ] Endpoint HTMX `GET /htmx/search?q=xxx` retournant un fragment HTML
- [ ] R√©sultats pertinents d√®s 2-3 caract√®res
- [ ] Tests unitaires sur la recherche (cas normaux + fuzzy + aucun r√©sultat)

**Notes techniques :**
- Utiliser `rapidfuzz` ou `difflib` pour le fuzzy matching
- Debounce c√¥t√© client (HTMX `hx-trigger="keyup changed delay:100ms"`)

**D√©pendances :** S-007

---

#### S-010 : Layout de base ‚Äî templates Jinja2, header, footer, CSS tokens

**Epic :** EPIC-002
**Priorit√© :** Must Have
**Points :** 3

**User Story :**
En tant qu'utilisateur,
je veux une interface sobre et professionnelle, coh√©rente sur tous les √©crans,
afin de consulter l'outil avec confiance.

**Crit√®res d'acceptation :**
- [ ] Template `base.html` : header, main, footer (disclaimer)
- [ ] CSS : design tokens (couleurs SFAR, typographie, espacement) en variables CSS
- [ ] HTMX inclus (`htmx.min.js`)
- [ ] Responsive : mobile-first, breakpoints 768px / 1024px
- [ ] Footer disclaimer permanent : "Outil de consultation ¬∑ Ne remplace pas le jugement clinique ¬∑ Source : RFE SFAR 2024"
- [ ] Navigation : logo + liens (Rechercher, Parcourir, Chat)

**Notes techniques :**
- Couleurs SFAR : `#273466` (primaire), `#0cc9bf` (accent), `#f15c40` (warning/allergie)
- Cf. design tokens dans le document UX

**D√©pendances :** Aucune (peut √™tre fait en parall√®le de S-007)

---

#### S-011 : √âcran d'accueil ‚Äî recherche + grille sp√©cialit√©s

**Epic :** EPIC-002
**Priorit√© :** Must Have
**Points :** 5

**User Story :**
En tant qu'anesth√©siste,
je veux arriver sur l'app et pouvoir imm√©diatement chercher ou parcourir les sp√©cialit√©s,
afin d'acc√©der au protocole le plus vite possible.

**Crit√®res d'acceptation :**
- [ ] Barre de recherche en autofocus (h√©ros de la page)
- [ ] R√©sultats type-ahead sous la barre (overlay HTMX)
- [ ] Grille des sp√©cialit√©s visible sous la recherche (cartes cliquables)
- [ ] Desktop : grille 4 colonnes ; Mobile : liste verticale
- [ ] Navigation clavier : fl√®ches dans les r√©sultats + Enter pour s√©lectionner

**D√©pendances :** S-009, S-010

---

#### S-012 : √âcran protocole ‚Äî d√©tail intervention

**Epic :** EPIC-002
**Priorit√© :** Must Have
**Points :** 3

**User Story :**
En tant qu'anesth√©siste au bloc,
je veux voir le protocole complet d'une intervention de mani√®re claire et scannable,
afin de confirmer la mol√©cule et la posologie en 2 secondes.

**Crit√®res d'acceptation :**
- [ ] URL propre : `/protocole/{id}`
- [ ] Composant ProtocolCard : mol√©cule en gros, tableau label/valeur
- [ ] Bloc allergie visuellement distinct (fond orang√©, bordure warning)
- [ ] Source cliquable (page PDF, tableau)
- [ ] Breadcrumb : Sp√©cialit√© > Intervention
- [ ] Responsive : blocs c√¥te √† c√¥te (desktop) / empil√©s (mobile)

**D√©pendances :** S-007, S-010

---

#### S-013 : √âcran sp√©cialit√© ‚Äî liste + toggle "tout d√©plier"

**Epic :** EPIC-002
**Priorit√© :** Must Have
**Points :** 3

**User Story :**
En tant qu'anesth√©siste,
je veux voir toutes les interventions d'une sp√©cialit√© avec leur aper√ßu,
afin de trouver le bon protocole m√™me sans conna√Ætre le nom exact.

**Crit√®res d'acceptation :**
- [ ] URL propre : `/specialite/{id}`
- [ ] Liste des interventions avec aper√ßu (mol√©cule principale)
- [ ] Bouton "Tout d√©plier" / "Tout replier" : affiche les protocoles complets inline
- [ ] Filtre local optionnel
- [ ] Chaque intervention cliquable ‚Üí √©cran protocole

**D√©pendances :** S-007, S-010, S-012 (r√©utilise ProtocolCard)

---

#### S-014 : Dockerfile + d√©ploiement NAS

**Epic :** EPIC-002
**Priorit√© :** Must Have
**Points :** 3

**User Story :**
En tant que porteur de projet,
je veux d√©ployer l'app sur mon NAS via Docker,
afin de la tester et la montrer √† mes coll√®gues sans co√ªt d'h√©bergement.

**Crit√®res d'acceptation :**
- [ ] `Dockerfile` multi-stage (build + runtime)
- [ ] `docker-compose.yml` pour le d√©ploiement local/NAS
- [ ] L'app d√©marre et fonctionne dans le conteneur
- [ ] Documentation dans le README : comment d√©ployer sur un NAS
- [ ] Health check Docker configur√©

**Notes techniques :**
- Image de base : `python:3.12-slim`
- Port expos√© : 8000
- Variables d'env pour la config (port, log level, etc.)

**D√©pendances :** S-007 + au moins un √©cran fonctionnel

---

### Milestone 3 : Module IA + MCP (EPIC-003)

> **Objectif :** Chatbot IA int√©gr√© avec sour√ßage, serveur MCP, et infrastructure pour l'√©tude comparative.
>
> **Livrable :** Chatbot fonctionnel + serveur MCP + donn√©es d'√©valuation pour la publication.

---

#### S-015 : Interface chatbot ‚Äî √©cran chat, bulles, HTMX

**Epic :** EPIC-003
**Priorit√© :** Must Have
**Points :** 5

**User Story :**
En tant qu'anesth√©siste,
je veux poser une question en langage naturel et recevoir une r√©ponse format√©e,
afin d'obtenir un protocole sans conna√Ætre le nom exact de l'intervention.

**Crit√®res d'acceptation :**
- [ ] √âcran chat accessible via bouton üí¨
- [ ] Bulles user (droite) et IA (gauche)
- [ ] Input en bas, toujours visible
- [ ] Indicateur de chargement pendant la r√©ponse
- [ ] Mobile : plein √©cran ; Desktop : √† d√©finir (plein √©cran ou panneau lat√©ral)
- [ ] Message d'accueil avec exemples de questions
- [ ] Historique de conversation (session navigateur)

**D√©pendances :** S-010

---

#### S-016 : Int√©gration LLM niveau 3 (tool use) ‚Äî r√©ponses sourc√©es

**Epic :** EPIC-003
**Priorit√© :** Must Have
**Points :** 8

**User Story :**
En tant qu'anesth√©siste,
je veux que le chatbot me r√©ponde avec le bon protocole ET cite sa source exacte,
afin d'avoir confiance dans la r√©ponse.

**Crit√®res d'acceptation :**
- [ ] Appel API Claude avec tool use (les outils de recherche dans les donn√©es)
- [ ] System prompt structur√© (cf. architecture section 8)
- [ ] 100% des r√©ponses incluent une source (page, tableau)
- [ ] "Je ne sais pas" si hors p√©rim√®tre (pas d'hallucination)
- [ ] R√©ponse format√©e avec carte protocole int√©gr√©e (r√©utilise le composant)
- [ ] Streaming SSE pour affichage progressif
- [ ] Rate limiting : 10 req/min par IP
- [ ] Temps de r√©ponse < 10s (NFR-002)
- [ ] Tests : questions in-scope, hors-scope, ambigu√´s

**Notes techniques :**
- Utiliser le SDK Anthropic Python
- Les tools correspondent aux fonctions de `app/data/search.py`
- Cl√© API en variable d'environnement

**D√©pendances :** S-008, S-015

---

#### S-017 : Serveur MCP

**Epic :** EPIC-003
**Priorit√© :** Must Have
**Points :** 5

**User Story :**
En tant que d√©veloppeur ou utilisateur de Claude Desktop,
je veux connecter un client MCP au serveur pour interroger les recommandations,
afin d'int√©grer les donn√©es dans mon workflow IA.

**Crit√®res d'acceptation :**
- [ ] Serveur MCP fonctionnel (`mcp_server/server.py`)
- [ ] Outils : `search_interventions`, `get_intervention`, `list_specialites`, `get_specialite`, `get_recommandations_generales`
- [ ] Connectable depuis Claude Desktop
- [ ] Documentation d'int√©gration dans le README
- [ ] Tests unitaires des outils MCP

**Notes techniques :**
- SDK : `mcp` (Python SDK officiel Anthropic)
- Processus s√©par√©, lit les m√™mes fichiers `data/rfe.json`

**D√©pendances :** S-007

---

#### S-018 : RAG niveau 1 (PDF) + niveau 2 (Excel)

**Epic :** EPIC-003
**Priorit√© :** Must Have
**Points :** 5

**User Story :**
En tant que chercheur,
je veux impl√©menter les approches RAG sur PDF brut et Excel,
afin de comparer leur fiabilit√© avec l'approche MCP structur√©e.

**Crit√®res d'acceptation :**
- [ ] RAG niveau 1 : PDF ‚Üí chunking ‚Üí embeddings ‚Üí ChromaDB ‚Üí contexte ‚Üí LLM
- [ ] RAG niveau 2 : Excel ‚Üí chunking ‚Üí embeddings ‚Üí ChromaDB ‚Üí contexte ‚Üí LLM
- [ ] Les deux approches r√©pondent aux m√™mes questions que le niveau 3
- [ ] R√©sultats enregistr√©s pour comparaison

**Notes techniques :**
- LangChain ou LlamaIndex pour le pipeline RAG
- ChromaDB embarqu√© (pas de service externe)
- Les embeddings peuvent utiliser l'API Anthropic ou un mod√®le local

**D√©pendances :** S-005 (Excel complet), S-016 (niveau 3 fonctionnel)

---

#### S-019 : Jeu de questions + √©valuation comparative

**Epic :** EPIC-003
**Priorit√© :** Must Have
**Points :** 5

**User Story :**
En tant que chercheur,
je veux √©valuer les 3 niveaux de structuration sur un jeu de questions standardis√©,
afin de mesurer l'impact de la structuration sur la fiabilit√© des r√©ponses.

**Crit√®res d'acceptation :**
- [ ] Jeu de 30-50 questions standardis√© dans `research/questions.json`
- [ ] Script d'√©valuation automatique (`research/evaluate.py`)
- [ ] R√©sultats par niveau : taux de r√©ponses correctes, hallucinations, "je ne sais pas"
- [ ] Export des r√©sultats en CSV/JSON dans `research/results/`
- [ ] Les r√©ponses de r√©f√©rence (ground truth) sont valid√©es par un clinicien

**Notes techniques :**
- Questions : mix de questions directes ("ATB pour PTH ?"), ambigu√´s ("je mets quoi pour la hanche ?"), hors p√©rim√®tre ("dosage de Doliprane ?")
- √âvaluation : comparaison automatique + validation clinicien

**D√©pendances :** S-016, S-018

---

## Tra√ßabilit√©

### Epics ‚Üí Stories

| Epic | Nom | Stories | Points |
|------|-----|---------|--------|
| EPIC-001 | Structuration des donn√©es | S-001 √† S-006 | 20 |
| EPIC-002 | Webapp + API REST | S-007 √† S-014 | 30 |
| EPIC-003 | Module IA + MCP | S-015 √† S-019 | 28 |
| **Total** | | **19 stories** | **78 points** |

### FRs ‚Üí Stories

| FR | Nom | Stories |
|----|-----|---------|
| FR-001 | Extraction donn√©es PDF | S-002, S-003, S-004, S-005 |
| FR-002 | Recommandations g√©n√©rales | S-006 |
| FR-003 | Recherche instantan√©e | S-009, S-011 |
| FR-004 | Navigation arborescence | S-011, S-013 |
| FR-005 | Affichage protocole | S-012 |
| FR-006 | Disclaimer m√©dical | S-010 |
| FR-007 | Chatbot | S-015, S-016 |
| FR-008 | Sour√ßage r√©ponses IA | S-016 |
| FR-009 | Comparaison 3 niveaux | S-018, S-019 |
| FR-010 | API REST | S-008 |
| FR-011 | Serveur MCP | S-017 |
| FR-012 | Open-source + docs | S-001 |

### NFRs ‚Üí Stories

| NFR | Nom | Stories |
|-----|-----|---------|
| NFR-001 | < 200ms recherche | S-009 |
| NFR-002 | < 10s chatbot | S-016 |
| NFR-003 | Pas de donn√©es sant√© | Transversal (aucun champ patient) |
| NFR-004 | Pas d'auth | Transversal (aucune route prot√©g√©e) |
| NFR-005 | Disponibilit√© 99% | S-014 |
| NFR-006 | Design responsive | S-010 |
| NFR-007 | Accessibilit√© > 80 | S-010 |
| NFR-008 | Code document√© | S-001 |
| NFR-009 | Mise √† jour donn√©es | S-002 (format JSON s√©par√©) |
| NFR-010 | < 20‚Ç¨/mois | S-014 (NAS), architecture globale |

---

## Risques

**√âlev√© :**
- Qualit√© de l'extraction PDF ‚Üí Mitigation : extraction tableau par tableau, validation clinique syst√©matique
- Hallucinations du chatbot ‚Üí Mitigation : tool use (pas de g√©n√©ration libre), tests rigoureux

**Moyen :**
- Performance du RAG sur PDF brut (niveau 1) ‚Üí Mitigation : c'est pr√©cis√©ment ce qu'on mesure
- Co√ªt API LLM si usage intensif ‚Üí Mitigation : routage Haiku/Sonnet, rate limiting

**Faible :**
- Disponibilit√© du NAS ‚Üí Mitigation : migration Docker vers le cloud triviale
- Compatibilit√© navigateurs ‚Üí Mitigation : HTMX fonctionne partout, pas de JS exotique

---

## Definition of Done

Pour qu'une story soit consid√©r√©e comme termin√©e :
- [ ] Code impl√©ment√© et pouss√© sur une branche `feat/xxx`
- [ ] Tests √©crits et passants (coverage > 80% sur la logique m√©tier)
- [ ] Lint (ruff) passant
- [ ] PR cr√©√©e via `gh pr create`
- [ ] CI verte
- [ ] Crit√®res d'acceptation valid√©s
- [ ] Merg√©e dans `main`

---

## Prochaines √©tapes

1. **Commencer par S-001** : `gh repo create`, structure, CI, CONTRIBUTING.md
2. Puis **S-002** : extraire le premier tableau en JSON (pilote)
3. Avancer story par story, au rythme du porteur de projet

Lancer `/bmad:dev-story S-001` pour commencer l'impl√©mentation.

---

*G√©n√©r√© par BMAD Method v6 ‚Äî Scrum Master*
*Date : 2026-02-16*
